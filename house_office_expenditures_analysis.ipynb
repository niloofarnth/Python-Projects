{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/niloofartehrani/Google Drive File Stream/My Drive/Programming/Data Incubator Challenge/house-office-expenditures-with-readme/'\n",
    "csv_files = [file for file in glob.glob(path +'*detail*.csv') if not file.endswith('2015Q2-house-disburse-detail.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for filename in csv_files:\n",
    "    data = pd.read_csv(filename,dtype = {\"BIOGUIDE_ID\": object},encoding = 'ISO-8859-1')\n",
    "    list_data.append(data)\n",
    "#data DataFrame is the main data before cleaning\n",
    "data = pd.concat(list_data,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the data\n",
    "data_clean = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizing the data for the 2017Q2 in the right columns\n",
    "data_clean[data_clean['QUARTER']=='2017Q2'] = data[data['QUARTER']=='2017Q2'].loc[:,['PURPOSE','BIOGUIDE_ID',\n",
    "          'CATEGORY','SORT SEQUENCE','START DATE','OFFICE','RECORDID','PROGRAM','END DATE','QUARTER','RECIP (orig.)',\n",
    "          'TRANSCODE','BIOGUIDE_ID','PAYEE','DATE','TRANSCODELONG','AMOUNT']].values\n",
    "#data_clean[data_clean['QUARTER']=='2017Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.AMOUNT = pd.to_numeric(data_clean['AMOUNT'], errors = 'coerce').round(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for changing to datetime format more efficiently\n",
    "def lookup(cl):\n",
    "    \"\"\"\n",
    "    This is an extremely fast approach to datetime parsing.\n",
    "    For large data, the same dates are often repeated. Rather than\n",
    "    re-parse these, we store all unique dates, parse them, and\n",
    "    use a lookup to convert all dates.\n",
    "    \"\"\"\n",
    "    dates = {date:pd.to_datetime(date, errors = 'coerce') for date in cl.unique()}\n",
    "    return cl.map(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to datetime format\n",
    "data_clean['START DATE'] = lookup(data_clean['START DATE'])\n",
    "data_clean['END DATE'] = lookup(data_clean['END DATE'])\n",
    "data_clean['DATE'] = lookup(data_clean['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the YEAR column and changing the data type\n",
    "data_clean.YEAR = data_clean.YEAR.str.extract('(\\d+)',expand=True)\n",
    "data_clean.YEAR = pd.to_numeric(data_clean['YEAR'], errors = 'coerce')\n",
    "data_clean = data_clean[(data_clean['YEAR']>2007) | (data_clean['YEAR'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the rows that have YEAR = NaN and replace them with the first 4 characters of QUARTER column if QUARTER\n",
    "#is not null and has 6 characters\n",
    "rep_VALUE_year = ((data_clean.loc[data_clean['YEAR'].isnull(),'QUARTER'].notnull())\n",
    "                  & (data_clean.loc[data_clean['YEAR'].isnull(),'QUARTER'].str.len() == 6))\n",
    "#find the index of the rows that should be replaced\n",
    "rep_VALUE_index = data_clean[data_clean['YEAR'].isnull()].index[rep_VALUE_year].tolist()\n",
    "#find the data to replace with\n",
    "rep_VALUE_with = data_clean['QUARTER'][data_clean['YEAR'].isnull()][rep_VALUE_year].str[0:4].astype(int)\n",
    "#replacing \n",
    "data_clean.loc[rep_VALUE_index,'YEAR'] = rep_VALUE_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st cleaning of QUARTER by using the END DATE column\n",
    "rep_quarter = data_clean.loc[data_clean['QUARTER'].str.len() <4]\n",
    "rep_quarter_index = rep_quarter.loc[data_clean['END DATE'].notnull()].index.tolist()\n",
    "data_clean.loc[rep_quarter_index, 'QUARTER'] = \\\n",
    "data_clean.loc[rep_quarter_index, 'END DATE'].dt.strftime('%Y') + data_clean.loc[rep_quarter_index, 'QUARTER']\n",
    "#2nd cleaning of QUARTER by using the YEAR column\n",
    "rep_quarter2 = data_clean.loc[data_clean['QUARTER'].str.len() <4]\n",
    "rep_quarter_index2 = rep_quarter2.loc[data_clean['YEAR'].notnull()].index.tolist()\n",
    "data_clean.loc[rep_quarter_index2, 'QUARTER'] = \\\n",
    "data_clean.loc[rep_quarter_index2, 'YEAR'].astype(int).astype(str) + data_clean.loc[rep_quarter_index2, 'QUARTER']\n",
    "#3rd cleaning\n",
    "#rep_quarter_index3 = data_clean['QUARTER'].loc[data_clean['QUARTER'].str.len() <4].index.tolist()\n",
    "#data_clean['QUARTER'].loc[rep_quarter_index3[0]-2:rep_quarter_index3[-1]+2].replace(r'^Q',method = 'ffill',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the PAYEE column\n",
    "data_clean['PAYEE'] = data_clean['PAYEE'].str.replace(',', '')\n",
    "data_clean['PAYEE'] = data_clean['PAYEE'].str.replace('.', '')\n",
    "data_clean['PAYEE'] = data_clean['PAYEE'].str.replace(' ', '')\n",
    "data_clean['PAYEE'] = data_clean['PAYEE'].str.replace('BOLTONCAROLINEH', 'BOULTONCAROLINEH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWERING THE QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the total of all the payments in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total of all the payments is: 5570079451.790002\n"
     ]
    }
   ],
   "source": [
    "tot_payment = round(data_clean['AMOUNT'].sum(),10)\n",
    "print('The total of all the payments is: {}'.format(tot_payment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was the average annual expenditure with a 'START DATE' date between January 1, 2010 and December 31, 2016 (inclusive)? Only consider payments with strictly positive amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the annual expenditure between January 1, 2010 and December 31, 2016 is: 408.7948153241\n"
     ]
    }
   ],
   "source": [
    "yearly_expense = data_clean.set_index('START DATE')\n",
    "yearly_expense = yearly_expense.loc['January 1,2010':'December 31, 2016', 'AMOUNT']\n",
    "yearly_expense = yearly_expense[yearly_expense>= 0]\n",
    "annual_exp = yearly_expense.resample('A').mean()\n",
    "mean_annual_exp = round(annual_exp.mean(),10)\n",
    "print('the annual expenditure between January 1, 2010 and December 31, 2016 is: {}'.format(mean_annual_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was the highest average staff salary among all representatives in 2016? Assume staff sizes is equal to the number of unique payees in the 'PERSONNEL COMPENSATION' category for each representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest average staff salary among all representatives in 2016: 3683.332\n"
     ]
    }
   ],
   "source": [
    "staff_salary_2016 = data_clean.loc[data_clean['START DATE'].dt.year == 2016,:]\n",
    "staff_size_data = staff_salary_2016[staff_salary_2016['CATEGORY']=='PERSONNEL COMPENSATION']\n",
    "staff_size = staff_size_data.groupby('BIOGUIDE_ID')['PAYEE'].nunique()\n",
    "staff_salary_per_rep = staff_size_data.groupby(['BIOGUIDE_ID','PAYEE'])['AMOUNT'].sum()\n",
    "max_staff_salary = round((staff_salary_per_rep/staff_size).max(),10)\n",
    "print('The highest average staff salary among all representatives in 2016: {}'.format(max_staff_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the 'COVERAGE PERIOD' for each payment as the difference (in days) between 'END DATE' and 'START DATE'. What is the standard deviation in 'COVERAGE PERIOD'? Only consider payments with strictly positive amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation in \"COVERAGE PERIOD\" is: 58.3976096228\n"
     ]
    }
   ],
   "source": [
    "coverage_data = data_clean.loc[data_clean['AMOUNT']>=0,['START DATE','END DATE']]\n",
    "coverage_data['COVERAGE PERIOD'] = data_clean['END DATE'] - data_clean['START DATE']\n",
    "coverage_std = coverage_data['COVERAGE PERIOD'].std()\n",
    "coverage_std_sec = coverage_std.days*24*3600 + coverage_std.seconds + coverage_std.microseconds/10**6\n",
    "coverage_std_days = round(coverage_std_sec/(3600*24),10)\n",
    "print('The standard deviation in \"COVERAGE PERIOD\" is: {}'.format(coverage_std_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the 'OFFICE' with the highest total expenditures with a 'START DATE' in 2016. For this office, find the 'PURPOSE' that accounts for the highest total expenditures. What fraction of the total expenditures (all records, all offices) with a 'START DATE' in 2016 do these expenditures amount to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction is: 0.0739107351\n"
     ]
    }
   ],
   "source": [
    "office_data = data_clean.loc[data_clean['START DATE'].dt.year == 2016,:]\n",
    "max_exp_officename = office_data.groupby('OFFICE')['AMOUNT'].sum().sort_values(ascending = False).index[0]\n",
    "max_exp_office_data = office_data.loc[office_data['OFFICE'] == max_exp_officename,:]\n",
    "max_exp_purpose = max_exp_office_data.groupby('PURPOSE')['AMOUNT'].sum().max()\n",
    "tot_exp = office_data['AMOUNT'].sum()\n",
    "exp_frac = round(max_exp_purpose/tot_exp,10)\n",
    "print('The fraction is: {}'.format(exp_frac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was the median rate of annual turnover in staff between 2011 and 2016 (inclusive)? Turnover for 2011 should be calculated as the fraction of a representative's staff from 2010 who did not carry over to 2011. Only consider representatives who served for at least 4 years and had staff size of at least 5 every year that they served."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning some suspicious data\n",
    "data_clean.loc[data_clean['START DATE'].dt.year==2061,'START DATE'] = data_clean.loc[data_clean['START DATE'].dt.year==2061,'START DATE']- pd.DateOffset(years=50)\n",
    "data_clean.loc[data_clean['START DATE'].dt.year==2051,'START DATE'] = data_clean.loc[data_clean['START DATE'].dt.year==2051,'START DATE']- pd.DateOffset(years=36)\n",
    "data_clean.loc[data_clean['START DATE'].dt.year==2044,'START DATE'] = data_clean.loc[data_clean['START DATE'].dt.year==2044,'START DATE']- pd.DateOffset(years=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I assumed that the 4 year serving condition and the staff size of 5 is between applied to the years between 2011 and 2016\n",
    "rep_data = data_clean.groupby(data_clean['START DATE'].dt.year)['BIOGUIDE_ID'].unique()\n",
    "\n",
    "years = list(range(2011,2017))\n",
    "idx = [i for i in data_clean['BIOGUIDE_ID'].unique() if str(i) != 'nan']\n",
    "\n",
    "rep_serv_year = pd.DataFrame(0, index=idx, columns= years)\n",
    "for y in sorted(years):\n",
    "    for i in range(len(rep_serv_year)):\n",
    "        if rep_serv_year.index[i] in rep_data[y]:\n",
    "            rep_serv_year.loc[rep_serv_year.index[i],y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_staff_size_data = data_clean[data_clean['CATEGORY']=='PERSONNEL COMPENSATION']\\\n",
    "                        .groupby([data_clean['START DATE'].dt.year,'BIOGUIDE_ID'])['PAYEE'].nunique()\n",
    "\n",
    "idx2 = rep_staff_size_data.index.get_level_values(1).unique()\n",
    "rep_staff_size = pd.DataFrame(0, index=idx2, columns= years)\n",
    "\n",
    "for y in years:\n",
    "    for i in rep_staff_size_data.loc[y].index:\n",
    "        if rep_staff_size_data.loc[y,i]>=5:\n",
    "            rep_staff_size.loc[i,y] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = rep_staff_size.index.intersection(rep_serv_year.index)\n",
    "conditions = pd.DataFrame()\n",
    "conditions['total years served'] = rep_serv_year.loc[reps,years].sum(axis =1)\n",
    "conditions['#years of staff size = 5'] = rep_staff_size.loc[reps,years].sum(axis =1)\n",
    "conditions['conditions met'] = (conditions['total years served'] == conditions['#years of staff size = 5']) & \\\n",
    "                            (conditions['total years served'] >= 4)\n",
    "reps = conditions[conditions['conditions met'] == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the median rate of annual turnover in staff between 2011 and 2016 is: 0.2354594634\n"
     ]
    }
   ],
   "source": [
    "turnover_data = data_clean.loc[(data_clean['START DATE'].dt.year >= 2010) \\\n",
    "                             & (data_clean['START DATE'].dt.year <= 2016) \\\n",
    "                             & (data_clean['BIOGUIDE_ID'].isin(list(reps)))\\\n",
    "                             & (data_clean['CATEGORY']=='PERSONNEL COMPENSATION'),:]\n",
    "turnover_data = turnover_data.dropna(subset = ['PAYEE'])\n",
    "turnover_per_year_reps = pd.Series(index = years)\n",
    "for y in range(2010,2016):\n",
    "    year1_staff = turnover_data.loc[turnover_data['START DATE'].dt.year == y].groupby('BIOGUIDE_ID')['PAYEE'].unique()\n",
    "    year2_staff = turnover_data.loc[turnover_data['START DATE'].dt.year == y+1].groupby('BIOGUIDE_ID')['PAYEE'].unique()\n",
    "    staff_list_year1 = []\n",
    "    staff_list_year2 = []\n",
    "    for rep in reps:\n",
    "        if (rep in year1_staff.keys()) and (rep in year2_staff.keys()): \n",
    "            staff_list_year1 += list(year1_staff[rep])\n",
    "            staff_list_year2 += list(year2_staff[rep])\n",
    "    turnover_frac_rep = (len(set(staff_list_year1)) - len(set(staff_list_year1).intersection(set(staff_list_year2))))\\\n",
    "                             /(len(set(staff_list_year1)))\n",
    "    turnover_per_year_reps[y+1] = turnover_frac_rep                    \n",
    "        \n",
    "\n",
    "median_turnover_rate = round(turnover_per_year_reps.median(),10)\n",
    "print('the median rate of annual turnover in staff between 2011 and 2016 is: {}'.format(median_turnover_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What percentage of the expenditures of the top 20 spenders in 2016 come from members of the Democratic Party? Representatives are identified by their 'BIOGUIDE_ID', which can be used to look up representatives with ProPublica's Congress API to find their party affiliation. Consider an expenditure as being in 2016 if its 'START DATE' is in 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_spenders_2016 = data_clean.loc[data_clean['START DATE'].dt.year == 2016]\n",
    "top_spenders_2016 = top_spenders_2016.groupby('BIOGUIDE_ID')['AMOUNT'].sum()\n",
    "top_spenders_2016 = top_spenders_2016.sort_values(ascending = False)[0:20]\n",
    "top_spenders = top_spenders_2016.keys()\n",
    "reps_parties = pd.DataFrame(top_spenders_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of the expenditures of the top 20 spenders in 2016 is: 33.4165808451\n"
     ]
    }
   ],
   "source": [
    "for rep in list(top_spenders):\n",
    "    url = \"https://api.propublica.org/congress/v1/members/{}.json\".format(rep)\n",
    "    r = requests.get(url, headers={'X-API-Key':'1yk2z0GoZu7Kvcst1UobxPrrCV3fBParGwOVxsnZ'})\n",
    "    json_data = r.json()\n",
    "    member = json_data['results'][0]['member_id']\n",
    "    party =  json_data['results'][0]['roles'][0]['party']\n",
    "    reps_parties.loc[member,'party'] = party\n",
    "\n",
    "democrat_spender_perc = ((reps_parties['AMOUNT'][reps_parties['party'] == 'D'].sum())/(reps_parties['AMOUNT'].sum()))*100\n",
    "print('The percentage of the expenditures of the top 20 spenders in 2016 is: {}'.format(round(democrat_spender_perc,10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
